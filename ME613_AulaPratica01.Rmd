---
title: "ME613A - Análise de Regressão"
author: "Profa. Tatiana Benaglia"
date: "Atividade Prática 01 - 2S2023 - 16/08/2023"
output:
  html_document: default
  pdf_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introdução 

Uma empresa de pesquisa (Last Resource, Inc., Bellefonte, PA) fez um estudo para verificar qual a relação entre a idade do motorista e a distância que ele consegue ver. 

Foi coletada uma amostra de $n = 30$ motoristas, na qual perguntaram a idade do motorista e mediram a distância (em pés) que eles conseguiam enxergar bem um sinal de trânsito. Esses dados estão disponíveis no Moodle, no arquivo chamado *signdist.txt*.


## Atividade

1. Leia o conjunto de dados no R e faça um gráfico de dispersão para visualizar a relação entre a idade (variável preditora $X$) e distância (variável resposta $Y$).

2. Calcule as estatísticas descritivas das variáveis e também o coeficiente de correlação entre elas.

3. Utilizando o R como uma calculadora simples, calcule as estatísticas de interesse que serão posteriormente utizadas para encontrar os estimadores de $\beta_0$ e $\beta_1$. 

4. Usando as estatísticas do item anterior, escreva uma função que, para um dado conjunto de dados, retorna as estimativas de $\hat \beta_0$ e $\hat \beta_1$. **Nota**: não usar a função `lm()`.

5. Ajuste o modelo de regressão linear simples utilizando a função `lm()` e compare os resultados obtidos no item 3. **Dica**: use as funções `summary()` ou `coef()` para visualizar os coeficientes estimados.

6. Apresente um gráfico de dispersão dos dados juntamente com a reta de regressão ajustada. Escreva um parágrafo com as interpretação dos parâmetros. **Nota**: utilize a função `geom_abline()`. Você não deve usar a função `geom_smooth()`.

7. Utilizando as fórmulas dadas em aula, encontre as estimativas das variâncias de $\varepsilon$, $\beta_0$ e $\beta_1$. Verifique os cálculos com os resultados apresentados na tabela dos coeficientes estimados obtida no R.

8. Encontre os intervalos de confiança de 90% para $\beta_0$ e $\beta_1$ da seguinte forma:
    (a) usando as fórmulas dadas em aula
    (b) usando a função `confint()`
    
9. Apresente um teste de hipótese para verificar se o coeficiente $\beta_1$ é nulo ou não, usando o seguinte:
    (a) Teste t
    (b) Teste F

10. Calcule o coeficiente de determinação $R^2$ e interprete-o.

11. Centralize a variável preditora em sua média e ajuste uma regressão simples novamente. Compare o resultado com aquele obtido no item 4.

12. Se você transformar a distância de pés para metros, como isso afeta os coeficientes da regressão? Note que 1 pé = 0,3048 metros.

```{r , echo=FALSE, message = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(readr)
library(tidyr)
library(tidyverse)
library(stringr)
library(magrittr)
library(lubridate)
library(knitr)
library(dplyr)
```

```{r , echo=FALSE, message = FALSE}
mydata <- read_table("~/Desktop/Analise de Regressao/Atividade/signdist.txt")
```

```{r }
desc <- function(x){
  n <- length(x)
  summary <- summary(x)
  variance <- var(x)
  sd <- sd(x)
  cv <- (sd/mean(x))*100
  iqr <- IQR(x)
  return(c(n=n, summary, variance = variance, std.dev = sd, inter.quart.range = iqr, var.coef = cv))
}

kable(apply(mydata, 2, desc), digits = 2)
```

```{r }
mydata %>% ggplot(aes(x=Age, y=Distance)) + geom_point() +
  labs(x= "Idade", y= "Distância") +
  theme_bw()
```

```{r }
cor(x=mydata$Age, y=mydata$Distance)
```

```{r }
y_barra <- mean(mydata$Distance)
x_barra <- mean(mydata$Age)
sum_xi <- sum(mydata$Age)
sum_yi <- sum(mydata$Distance)
sum_xiyi <-sum((mydata$Age)*(mydata$Distance))
sum_xi2 <- sum((mydata$Age)*(mydata$Age))
sxx <- sum(((mydata$Age)-(x_barra))^2)
obs <- 30
```
 retorna as estimativas de $\hat \beta_0$ e $\hat \beta_1$. **Nota**: não usar a função `lm()`.

```{r }
estatisticas <- c(y_barra, x_barra, sum_xiyi, sxx, obs)
estimadores <- function(estatisticas){
  hat_beta_1 <- (sum_xiyi - obs*((x_barra)*(y_barra)))/sxx
  hat_beta_0 <- y_barra - (hat_beta_1*x_barra)
  estimativas <- c(hat_beta_0, hat_beta_1)
  return(estimativas)
  }
estimadores(estatisticas)
```

```{r }
model_distancia <- lm(Distance ~ Age, data = mydata)
summary(model_distancia)

model_distancia_sembeta0 <- lm(Distance ~ -1 + Age, data = mydata) # modelo sem intercepto
```
```{r }
coef(model_distancia)
```

```{r }
#MSE:
#modo1
sum(residuals(model_distancia)^2)/(30-2)
#modo2
summary(model_distancia)$sigma^2
```
# Com abline
```{r }
mydata %>% ggplot(aes(x=Age, y=Distance)) + geom_point() +
  geom_abline(intercept = 576.6819, slope = -3.0068, col = "red") +
  labs(x= "Idade", y= "Distância") +
  theme_bw()
```
#Com geom_smooth
```{r }
mydata %>% ggplot(aes(x=Age, y=Distance)) + geom_point() +
  geom_smooth(method = lm, se = FALSE, col = "red") +
  labs(x= "Idade", y= "Distância") +
  theme_bw()
```

```{r }
#varepsilon = MSE
y.estimado<- function(x){
  y_hat<-rep(0, length(x))
  for (i in 1:length(x)){
    y_hat[i] <- 576.6819 - 3.0068*x[i]
  }
  return(y_hat)
}

mydata$y_hat <- y.estimado(mydata$Age)

MSE <- (sum(((mydata$Distance) - (mydata$y_hat))^2))/(obs-2)
MSE

# no modelo, faz (Residual standard error)^2

```


```{r }
#varbeta0
vetor<-c(MSE, obs, x_barra, sxx)

var.beta0.hat <- function(vetor){
  var <- MSE*((1/obs)+(((x_barra)^2)/sxx))
  return(var)
}

variancia.beta0 <- var.beta0.hat(vetor)

```

```{r }
#varbeta1
var.beta1.hat <- function(vetor){
  var <- MSE*(1/sxx)
  return(var)
}

variancia.beta1 <- var.beta1.hat(vetor)
```

```{r }
#Manualmente
betas<-estimadores(estatisticas)
tcrit <- qt(p = 0.1/2, df = 28, lower.tail = FALSE)

c("lower" = betas[1] - tcrit*sqrt(variancia.beta0), "upper" = betas[1] + tcrit*sqrt(variancia.beta0))
c("lower" = betas[2] - tcrit*sqrt(variancia.beta1), "upper" = betas[2] + tcrit*sqrt(variancia.beta1))

# Usando confint():
#para beta0 e beta1
confint(model_distancia, level=0.90)
```

9. Apresente um teste de hipótese para verificar se o coeficiente $\beta_1$ é nulo ou não, usando o seguinte:
    (a) Teste t
    (b) Teste F
```{r }

```

```{r }
r <- cor(x=mydata$Age, y=mydata$Distance)
r

r2 <- r^2 
r2 # 64% da variancia dos dados é explicado pelo modelo
```

11. Centralize a variável preditora em sua média e ajuste uma regressão simples novamente. Compare o resultado com aquele obtido no item 4.

```{r }

```
    
12. Se você transformar a distância de pés para metros, como isso afeta os coeficientes da regressão? Note que 1 pé = 0,3048 metros.
```{r }

```

```{r }

```

